{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning in Bioinformatics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2: \n",
    " !!! If you don't fill these fields, your homework does not count !!!<by/>\n",
    " #### first name and last name : Monireh Safari\n",
    " #### student number : 98201803"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run cells by hitting `Shift` + `Enter` or `ctrl` + `Enter`. <br/>\n",
    "We highly recommend you to read each line of code carefully and try to understand what it exactly does. <br/>\n",
    "Just alter the parts that is between green comments and specified for you. Please do not change other parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1. soft margin SVM\n",
    "### about the Data:<br/>\n",
    "The purpose of this project is to classify tumors into malignant or benign. The following dataset is constructed based on images of tumors. Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.\n",
    "For more details about the features of this dataset you can visit this link:\n",
    "https://scikit-learn.org/stable/datasets/index.html#breast-cancer-dataset<br/>\n",
    "This dataset contains 30 features and 1 label that is called target. We should find a proper hyperplane that separates malignant and benign samples.\n",
    "The original dataset labels is 0 and 1 and in the following code boxes we change it to -1 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension   ...    worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871   ...            17.33           184.60      2019.0   \n",
       "1                 0.05667   ...            23.41           158.80      1956.0   \n",
       "2                 0.05999   ...            25.53           152.50      1709.0   \n",
       "3                 0.09744   ...            26.50            98.87       567.7   \n",
       "4                 0.05883   ...            16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890     0.0  \n",
       "1          0.2750                  0.08902     0.0  \n",
       "2          0.3613                  0.08758     0.0  \n",
       "3          0.6638                  0.17300     0.0  \n",
       "4          0.2364                  0.07678     0.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer = load_breast_cancer()\n",
    "df = pd.DataFrame(np.c_[cancer[\"data\"], cancer[\"target\"]], columns = np.append(cancer[\"feature_names\"],[\"target\"]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71.8804920913884 %\n",
      "71.8804920913884 %\n",
      "20.035149384885763 %\n",
      "20.035149384885763 %\n",
      "8.084358523725834 %\n",
      "8.084358523725834 %\n"
     ]
    }
   ],
   "source": [
    "cancer.target = np.where(cancer.target==0, -1, cancer.target) \n",
    "X_train ,X_test ,X_val ,y_train ,y_test ,y_val = None ,None ,None ,None ,None ,None\n",
    "################################################################################\n",
    "# TODO: using train_test_split package, split your data into 3 numpy array     #\n",
    "# called X_train, X_test, and X_val and also split the corresponding labels as #\n",
    "# y_train, y_test, and y_val. After spliting, the ratio of your data should be # \n",
    "# approximately like this:                                                     #\n",
    "#  Train : 72%     test : 20%       validation : 8%                            #\n",
    "################################################################################\n",
    "\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=1)\n",
    "\n",
    "\n",
    "################################################################################\n",
    "#                                 END OF YOUR CODE                             #\n",
    "################################################################################\n",
    "print((X_train.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((y_train.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((X_test.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((y_test.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((X_val.shape[0]/cancer.data.shape[0]) * 100, \"%\")\n",
    "print((y_val.shape[0]/cancer.data.shape[0]) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### soft margin SVM optimization:<br/>\n",
    "We add 1 at the beginning of each Xs data (X_train, X_val , ...) and then the bias will be calculated implicitly.\n",
    "Then you should minimize the following SVM loss function (using gradient descent) with changing parameters of model.<br>\n",
    "In this notation: \n",
    "\\begin{equation}\n",
    "x_i , y_i\n",
    "\\end{equation}\n",
    "refers to feature vector of the sample and the label of our training data<br>\n",
    "and this is SVM loss function:\n",
    "\n",
    "\\begin{equation}\n",
    "\\large\n",
    "J(W) = \\frac{1}{N} \\sum_{i=1}^{N}{L^{(i)}} + \\frac{\\lambda}{2} ||W||^2\\\\\n",
    "\\large\n",
    "L^{(i)} ={max(0, 1 - y_i(w^{T}x_i)})\n",
    "\\;\\\\\n",
    "\\end{equation} \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(409, 31)\n",
      "(46, 31)\n",
      "(114, 31)\n"
     ]
    }
   ],
   "source": [
    "# >>>>>WARNING: RUN THIS CELL ONLY ONCE!<<<<<\n",
    "\n",
    "# adding 1s to the end of feature vectors to be multiplied by bias term of weights\n",
    "\n",
    "X_val = np.insert(X_val, 0, 1, axis=1)\n",
    "X_train = np.insert(X_train, 0, 1, axis=1)\n",
    "X_test = np.insert(X_test, 0, 1, axis=1)\n",
    "print(X_train.shape)  \n",
    "print(X_val.shape)  \n",
    "print(X_test.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Complete the following functions in SVM class. In the part that you should compute loss function of this class, you are not allowed to use \"for\" loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-12T16:30:29.561420Z",
     "start_time": "2020-03-12T16:30:29.538696Z"
    }
   },
   "outputs": [],
   "source": [
    "from numpy import linalg as LA\n",
    "\n",
    "\n",
    "class SVM:\n",
    "    def __init__(self, n_features: int, std: float):\n",
    "        \"\"\"\n",
    "        n_features: number of features in (or the dimension of) each instance\n",
    "        std: standard deviation used in the initialization of the weights of svm\n",
    "        \"\"\"\n",
    "        self.n_features = n_features\n",
    "        ################################################################################\n",
    "        # TODO: Initialize the weights of svm using random normal distribution with    #\n",
    "        # standard deviation equals to std.                                            #\n",
    "        ################################################################################\n",
    "        self.w = np.random.normal(0, std, n_features).reshape(n_features, 1)\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "\n",
    "    def loss(self, X: np.ndarray, y: np.ndarray, reg_coeff: float):\n",
    "        \"\"\"\n",
    "        X: training instances as a 2d-array with shape (num_train, n_features)\n",
    "        y: labels corresponsing to the given training instances as a 1d-array with shape (num_train,)\n",
    "        reg_coeff: L2-regularization coefficient\n",
    "        \"\"\"\n",
    "        loss = 0.0\n",
    "        \n",
    "        #################################################################################\n",
    "        # TODO: Compute the hinge loss specified in the notebook and save it in the loss#                                                   # loss variable.                                                               #\n",
    "        # NOTE: YOU ARE NOT ALLOWED TO USE FOR LOOPS!                                   #\n",
    "        # Don't forget L2-regularization term in your implementation!                   #\n",
    "        #################################################################################\n",
    "\n",
    "        N = X.shape[0]\n",
    "        y = y.reshape(y.shape[0], 1)\n",
    "        L = 1 - y * np.dot(X, self.w)\n",
    "        L[L < 0] = 0\n",
    "        loss = (1 / N) * np.sum(L) + ( reg_coeff / 2 ) * (LA.norm(self.w) ** 2)\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "        return loss\n",
    "        \n",
    "    def update_weights(self,  X: np.ndarray, y: np.ndarray, learning_rate: float , reg_coeff: float):\n",
    "        \"\"\"\n",
    "        Updates the weights of the svm using the gradient of computed loss with respect to the weights. \n",
    "        learning_rate: learning rate that will be used in gradient descent to update the weights\n",
    "        \"\"\"\n",
    "        ################################################################################\n",
    "        # TODO: Compute the gradient of loss computed above w.r.t the svm weights.     #\n",
    "        # and then update self.w with the computed gradient.                           #\n",
    "        # (don't forget learning rate and reg_coeff in update rule)                    #\n",
    "        # Don't forget L2-regularization term in your implementation!                  #\n",
    "        ################################################################################\n",
    "        \n",
    "        N = X.shape[0]\n",
    "        y = y.reshape(len(y), 1)\n",
    "        for i in range(N):\n",
    "            pred_y = y[i] * np.dot(X[i], self.w)\n",
    "            if pred_y[0] < 1:\n",
    "                self.w = self.w -  learning_rate * (reg_coeff * self.w - (y[i] * X[i]).reshape(self.n_features, 1))\n",
    "            else:\n",
    "                self.w = self.w - learning_rate * reg_coeff * self.w\n",
    "                \n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        X: Numpy 2d-array of instances\n",
    "        \"\"\"\n",
    "        y_pred = None\n",
    "        ################################################################################\n",
    "        # TODO: predict the labels for the instances in X and save them in y_pred.     #                                      #\n",
    "        ################################################################################\n",
    "        y = np.dot(X, self.w)\n",
    "        y_pred = [np.sign(y[i]) for i in range(len(X))]\n",
    "\n",
    "\n",
    "        ################################################################################\n",
    "        #                                 END OF YOUR CODE                             #\n",
    "        ################################################################################\n",
    "        return y_pred\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cell contains your hyper parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = 0.0001\n",
    "num_iters = 10000\n",
    "reg_coeff = 20\n",
    "learning_rate=1e-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this cell using your SVM class, we want to train our model for cancer data:<br/>\n",
    "In every iteration you should see your training loss decrease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, loss 1.029086, val acc 69.57%\n",
      "iteration 100, loss 0.428203, val acc 86.96%\n",
      "iteration 200, loss 0.315189, val acc 89.13%\n",
      "iteration 300, loss 0.275019, val acc 89.13%\n",
      "iteration 400, loss 0.257066, val acc 89.13%\n",
      "iteration 500, loss 0.245468, val acc 89.13%\n",
      "iteration 600, loss 0.237155, val acc 89.13%\n",
      "iteration 700, loss 0.231310, val acc 89.13%\n",
      "iteration 800, loss 0.226721, val acc 86.96%\n",
      "iteration 900, loss 0.223917, val acc 89.13%\n",
      "iteration 1000, loss 0.222167, val acc 89.13%\n",
      "iteration 1100, loss 0.220898, val acc 89.13%\n",
      "iteration 1200, loss 0.219794, val acc 89.13%\n",
      "iteration 1300, loss 0.218775, val acc 89.13%\n",
      "iteration 1400, loss 0.217933, val acc 89.13%\n",
      "iteration 1500, loss 0.217155, val acc 89.13%\n",
      "iteration 1600, loss 0.216543, val acc 89.13%\n",
      "iteration 1700, loss 0.215970, val acc 89.13%\n",
      "iteration 1800, loss 0.215510, val acc 89.13%\n",
      "iteration 1900, loss 0.215119, val acc 89.13%\n",
      "iteration 2000, loss 0.214787, val acc 89.13%\n",
      "iteration 2100, loss 0.214492, val acc 89.13%\n",
      "iteration 2200, loss 0.214201, val acc 89.13%\n",
      "iteration 2300, loss 0.213873, val acc 89.13%\n",
      "iteration 2400, loss 0.213577, val acc 89.13%\n",
      "iteration 2500, loss 0.213322, val acc 89.13%\n",
      "iteration 2600, loss 0.213116, val acc 89.13%\n",
      "iteration 2700, loss 0.212920, val acc 89.13%\n",
      "iteration 2800, loss 0.212721, val acc 89.13%\n",
      "iteration 2900, loss 0.212546, val acc 89.13%\n",
      "iteration 3000, loss 0.212475, val acc 89.13%\n",
      "iteration 3100, loss 0.212323, val acc 89.13%\n",
      "iteration 3200, loss 0.212246, val acc 89.13%\n",
      "iteration 3300, loss 0.212165, val acc 89.13%\n",
      "iteration 3400, loss 0.212090, val acc 89.13%\n",
      "iteration 3500, loss 0.212003, val acc 89.13%\n",
      "iteration 3600, loss 0.211938, val acc 89.13%\n",
      "iteration 3700, loss 0.211879, val acc 89.13%\n",
      "iteration 3800, loss 0.211823, val acc 89.13%\n",
      "iteration 3900, loss 0.211766, val acc 89.13%\n",
      "iteration 4000, loss 0.211715, val acc 89.13%\n",
      "iteration 4100, loss 0.211664, val acc 89.13%\n",
      "iteration 4200, loss 0.211614, val acc 89.13%\n",
      "iteration 4300, loss 0.211572, val acc 89.13%\n",
      "iteration 4400, loss 0.211523, val acc 89.13%\n",
      "iteration 4500, loss 0.211471, val acc 89.13%\n",
      "iteration 4600, loss 0.211423, val acc 89.13%\n",
      "iteration 4700, loss 0.211377, val acc 89.13%\n",
      "iteration 4800, loss 0.211350, val acc 89.13%\n",
      "iteration 4900, loss 0.211303, val acc 89.13%\n",
      "iteration 5000, loss 0.211258, val acc 89.13%\n",
      "iteration 5100, loss 0.211213, val acc 89.13%\n",
      "iteration 5200, loss 0.211167, val acc 89.13%\n",
      "iteration 5300, loss 0.211144, val acc 89.13%\n",
      "iteration 5400, loss 0.211100, val acc 89.13%\n",
      "iteration 5500, loss 0.211059, val acc 89.13%\n",
      "iteration 5600, loss 0.211018, val acc 89.13%\n",
      "iteration 5700, loss 0.210973, val acc 89.13%\n",
      "iteration 5800, loss 0.210955, val acc 89.13%\n",
      "iteration 5900, loss 0.210916, val acc 89.13%\n",
      "iteration 6000, loss 0.210877, val acc 89.13%\n",
      "iteration 6100, loss 0.210836, val acc 89.13%\n",
      "iteration 6200, loss 0.210797, val acc 89.13%\n",
      "iteration 6300, loss 0.210782, val acc 89.13%\n",
      "iteration 6400, loss 0.210746, val acc 89.13%\n",
      "iteration 6500, loss 0.210709, val acc 89.13%\n",
      "iteration 6600, loss 0.210672, val acc 89.13%\n",
      "iteration 6700, loss 0.210636, val acc 89.13%\n",
      "iteration 6800, loss 0.210624, val acc 89.13%\n",
      "iteration 6900, loss 0.210588, val acc 89.13%\n",
      "iteration 7000, loss 0.210554, val acc 89.13%\n",
      "iteration 7100, loss 0.210521, val acc 89.13%\n",
      "iteration 7200, loss 0.210487, val acc 89.13%\n",
      "iteration 7300, loss 0.210479, val acc 89.13%\n",
      "iteration 7400, loss 0.210444, val acc 89.13%\n",
      "iteration 7500, loss 0.210411, val acc 89.13%\n",
      "iteration 7600, loss 0.210381, val acc 89.13%\n",
      "iteration 7700, loss 0.210348, val acc 89.13%\n",
      "iteration 7800, loss 0.210353, val acc 89.13%\n",
      "iteration 7900, loss 0.210318, val acc 89.13%\n",
      "iteration 8000, loss 0.210289, val acc 89.13%\n",
      "iteration 8100, loss 0.210260, val acc 89.13%\n",
      "iteration 8200, loss 0.210267, val acc 89.13%\n",
      "iteration 8300, loss 0.210236, val acc 89.13%\n",
      "iteration 8400, loss 0.210208, val acc 89.13%\n",
      "iteration 8500, loss 0.210178, val acc 89.13%\n",
      "iteration 8600, loss 0.210148, val acc 89.13%\n",
      "iteration 8700, loss 0.210128, val acc 89.13%\n",
      "iteration 8800, loss 0.210110, val acc 89.13%\n",
      "iteration 8900, loss 0.210081, val acc 89.13%\n",
      "iteration 9000, loss 0.210061, val acc 89.13%\n",
      "iteration 9100, loss 0.210044, val acc 89.13%\n",
      "iteration 9200, loss 0.210028, val acc 89.13%\n",
      "iteration 9300, loss 0.210011, val acc 89.13%\n",
      "iteration 9400, loss 0.209992, val acc 89.13%\n",
      "iteration 9500, loss 0.209949, val acc 89.13%\n",
      "iteration 9600, loss 0.209948, val acc 89.13%\n",
      "iteration 9700, loss 0.209917, val acc 89.13%\n",
      "iteration 9800, loss 0.209900, val acc 89.13%\n",
      "iteration 9900, loss 0.209882, val acc 89.13%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "model = SVM(n_features=X_train.shape[1], std= std )\n",
    "loss_history = []\n",
    "loss_val_history = []\n",
    "for it in range(num_iters):\n",
    "    loss = model.loss(X_train, y_train, reg_coeff)\n",
    "    loss_val = model.loss(X_val, y_val, reg_coeff)\n",
    "    if it % 100 == 0:\n",
    "        val_preds =  model.predict(X_val)\n",
    "        print('iteration %d, loss %f, val acc %.2f%%' % (it, loss,  accuracy_score(y_val,val_preds) * 100))\n",
    "    model.update_weights(X_train, y_train, learning_rate , reg_coeff)\n",
    "    loss_history.append(loss)\n",
    "    loss_val_history.append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####################################################################################\n",
    "# TODO: using matplotlib.pyplot package plot the training loss and validation loss #\n",
    "# using loss_loss_history and loss_val_history                                     #\n",
    "####################################################################################\n",
    "\n",
    "x = [i for i in range(num_iters) if i%10 == 0 ]\n",
    "\n",
    "y1 = [loss_val_history[i] for i in x]\n",
    "y2 = [loss_history[i] for i in x]\n",
    "plt.plot(x, y1)\n",
    "plt.plot(x, y2)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.title('loss value for SVM')\n",
    "plt.show()\n",
    "####################################################################################\n",
    "#                                 END OF YOUR CODE                                 #\n",
    "####################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1:\n",
    "With changing your hyper parameters, find a configuration of hyper parameters that cause your loss to increase after each iteration and then report that configuration in the next cell. Explain why our loss increases?\n",
    "Write your answer in \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "std = \"0.0001\" <br>\n",
    "num_iters = \"10000\"<br>\n",
    "reg_coeff = \"20\"<br>\n",
    "learning_rate = \"1e-5\"<br>\n",
    "\n",
    "loss increases with these values beacause of the high learning_rate.The loss value can not converges to the minimum value beacause of the high learning_rate so it increase and decrease in every step.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2:\n",
    "In this cell please explain the reason of this event<br>\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP : 70 TN : 34 FP : 8 FN : 2\n",
      "91.22807017543859\n"
     ]
    }
   ],
   "source": [
    "val_preds =  model.predict(X_test)\n",
    "###########################################################################################\n",
    "# TODO: find the Confusion Matrix between val_preds and real labels (y_test) for test data#\n",
    "# then report the accuracy of the model.                                                  #\n",
    "# you are not allowed to use any premade function for accuracy and confusion matrix       #\n",
    "###########################################################################################\n",
    "\n",
    "TP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "FP = 0\n",
    "for i, j in zip(val_preds, y_test):\n",
    "    if i == 1 and j == 1:\n",
    "        TP += 1\n",
    "    elif i == -1 and j == -1:\n",
    "        TN += 1\n",
    "    elif i == 1 and j == -1:\n",
    "        FP += 1\n",
    "    elif i == -1 and j == 1:\n",
    "        FN += 1\n",
    "\n",
    "print(\"TP :\",TP,\"TN :\",TN,\"FP :\",FP, \"FN :\",FN)\n",
    "\n",
    "acc = 0\n",
    "for i, j in zip(val_preds, y_test):\n",
    "    if i == j:\n",
    "        acc += 1\n",
    "        \n",
    "print((acc / len(val_preds)) * 100)\n",
    "\n",
    "###########################################################################################\n",
    "#                                END OF YOUR EXPLANATION                                  #\n",
    "###########################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next part, we sample from training data with certain size (batch size) instead of using all the training data in each iteration, and train our model on batch data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = 0.0001\n",
    "batch_size = 200\n",
    "num_iters = 15000\n",
    "reg_coeff = 0.1\n",
    "learning_rate=1e-8\n",
    "model = SVM(n_features=X_train.shape[1], std= std )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, loss 0.991177, val acc 30.43%\n",
      "iteration 100, loss 0.653374, val acc 86.96%\n",
      "iteration 200, loss 0.397724, val acc 86.96%\n",
      "iteration 300, loss 0.329643, val acc 86.96%\n",
      "iteration 400, loss 0.322143, val acc 89.13%\n",
      "iteration 500, loss 0.256475, val acc 89.13%\n",
      "iteration 600, loss 0.252232, val acc 89.13%\n",
      "iteration 700, loss 0.222424, val acc 86.96%\n",
      "iteration 800, loss 0.215309, val acc 89.13%\n",
      "iteration 900, loss 0.204841, val acc 89.13%\n",
      "iteration 1000, loss 0.241635, val acc 89.13%\n",
      "iteration 1100, loss 0.177413, val acc 89.13%\n",
      "iteration 1200, loss 0.236378, val acc 89.13%\n",
      "iteration 1300, loss 0.210344, val acc 89.13%\n",
      "iteration 1400, loss 0.152457, val acc 89.13%\n",
      "iteration 1500, loss 0.288323, val acc 89.13%\n",
      "iteration 1600, loss 0.290174, val acc 89.13%\n",
      "iteration 1700, loss 0.205193, val acc 89.13%\n",
      "iteration 1800, loss 0.264478, val acc 91.30%\n",
      "iteration 1900, loss 0.292342, val acc 89.13%\n",
      "iteration 2000, loss 0.221892, val acc 91.30%\n",
      "iteration 2100, loss 0.266303, val acc 89.13%\n",
      "iteration 2200, loss 0.223733, val acc 89.13%\n",
      "iteration 2300, loss 0.208334, val acc 89.13%\n",
      "iteration 2400, loss 0.253616, val acc 89.13%\n",
      "iteration 2500, loss 0.238814, val acc 89.13%\n",
      "iteration 2600, loss 0.201522, val acc 89.13%\n",
      "iteration 2700, loss 0.165251, val acc 89.13%\n",
      "iteration 2800, loss 0.165752, val acc 89.13%\n",
      "iteration 2900, loss 0.196318, val acc 91.30%\n",
      "iteration 3000, loss 0.182118, val acc 89.13%\n",
      "iteration 3100, loss 0.241762, val acc 89.13%\n",
      "iteration 3200, loss 0.183091, val acc 89.13%\n",
      "iteration 3300, loss 0.182588, val acc 89.13%\n",
      "iteration 3400, loss 0.201609, val acc 89.13%\n",
      "iteration 3500, loss 0.232680, val acc 89.13%\n",
      "iteration 3600, loss 0.232554, val acc 89.13%\n",
      "iteration 3700, loss 0.186360, val acc 89.13%\n",
      "iteration 3800, loss 0.199781, val acc 89.13%\n",
      "iteration 3900, loss 0.187687, val acc 89.13%\n",
      "iteration 4000, loss 0.193606, val acc 89.13%\n",
      "iteration 4100, loss 0.227445, val acc 89.13%\n",
      "iteration 4200, loss 0.181495, val acc 89.13%\n",
      "iteration 4300, loss 0.239764, val acc 89.13%\n",
      "iteration 4400, loss 0.155920, val acc 89.13%\n",
      "iteration 4500, loss 0.210955, val acc 89.13%\n",
      "iteration 4600, loss 0.184622, val acc 89.13%\n",
      "iteration 4700, loss 0.198174, val acc 89.13%\n",
      "iteration 4800, loss 0.167562, val acc 89.13%\n",
      "iteration 4900, loss 0.230436, val acc 89.13%\n",
      "iteration 5000, loss 0.196992, val acc 89.13%\n",
      "iteration 5100, loss 0.174983, val acc 89.13%\n",
      "iteration 5200, loss 0.224615, val acc 89.13%\n",
      "iteration 5300, loss 0.229800, val acc 89.13%\n",
      "iteration 5400, loss 0.257778, val acc 89.13%\n",
      "iteration 5500, loss 0.181777, val acc 89.13%\n",
      "iteration 5600, loss 0.258008, val acc 89.13%\n",
      "iteration 5700, loss 0.150648, val acc 89.13%\n",
      "iteration 5800, loss 0.109485, val acc 89.13%\n",
      "iteration 5900, loss 0.180031, val acc 89.13%\n",
      "iteration 6000, loss 0.160652, val acc 89.13%\n",
      "iteration 6100, loss 0.185457, val acc 89.13%\n",
      "iteration 6200, loss 0.130746, val acc 89.13%\n",
      "iteration 6300, loss 0.235132, val acc 89.13%\n",
      "iteration 6400, loss 0.153940, val acc 89.13%\n",
      "iteration 6500, loss 0.193661, val acc 89.13%\n",
      "iteration 6600, loss 0.203467, val acc 89.13%\n",
      "iteration 6700, loss 0.173506, val acc 89.13%\n",
      "iteration 6800, loss 0.226972, val acc 89.13%\n",
      "iteration 6900, loss 0.253060, val acc 89.13%\n",
      "iteration 7000, loss 0.176679, val acc 89.13%\n",
      "iteration 7100, loss 0.139349, val acc 89.13%\n",
      "iteration 7200, loss 0.162776, val acc 89.13%\n",
      "iteration 7300, loss 0.177346, val acc 89.13%\n",
      "iteration 7400, loss 0.154977, val acc 89.13%\n",
      "iteration 7500, loss 0.223625, val acc 89.13%\n",
      "iteration 7600, loss 0.224439, val acc 89.13%\n",
      "iteration 7700, loss 0.198755, val acc 89.13%\n",
      "iteration 7800, loss 0.174418, val acc 89.13%\n",
      "iteration 7900, loss 0.222261, val acc 89.13%\n",
      "iteration 8000, loss 0.175504, val acc 89.13%\n",
      "iteration 8100, loss 0.195247, val acc 89.13%\n",
      "iteration 8200, loss 0.240189, val acc 89.13%\n",
      "iteration 8300, loss 0.167589, val acc 89.13%\n",
      "iteration 8400, loss 0.245762, val acc 89.13%\n",
      "iteration 8500, loss 0.178011, val acc 89.13%\n",
      "iteration 8600, loss 0.236171, val acc 89.13%\n",
      "iteration 8700, loss 0.170684, val acc 89.13%\n",
      "iteration 8800, loss 0.194950, val acc 89.13%\n",
      "iteration 8900, loss 0.150812, val acc 89.13%\n",
      "iteration 9000, loss 0.240038, val acc 89.13%\n",
      "iteration 9100, loss 0.175057, val acc 89.13%\n",
      "iteration 9200, loss 0.270505, val acc 89.13%\n",
      "iteration 9300, loss 0.219216, val acc 89.13%\n",
      "iteration 9400, loss 0.157725, val acc 89.13%\n",
      "iteration 9500, loss 0.240801, val acc 89.13%\n",
      "iteration 9600, loss 0.122708, val acc 89.13%\n",
      "iteration 9700, loss 0.183221, val acc 89.13%\n",
      "iteration 9800, loss 0.192634, val acc 89.13%\n",
      "iteration 9900, loss 0.173422, val acc 89.13%\n",
      "iteration 10000, loss 0.227485, val acc 89.13%\n",
      "iteration 10100, loss 0.147202, val acc 89.13%\n",
      "iteration 10200, loss 0.202603, val acc 89.13%\n",
      "iteration 10300, loss 0.249330, val acc 89.13%\n",
      "iteration 10400, loss 0.186162, val acc 89.13%\n",
      "iteration 10500, loss 0.150823, val acc 89.13%\n",
      "iteration 10600, loss 0.162477, val acc 89.13%\n",
      "iteration 10700, loss 0.218408, val acc 89.13%\n",
      "iteration 10800, loss 0.221099, val acc 89.13%\n",
      "iteration 10900, loss 0.195098, val acc 89.13%\n",
      "iteration 11000, loss 0.256842, val acc 89.13%\n",
      "iteration 11100, loss 0.169163, val acc 89.13%\n",
      "iteration 11200, loss 0.221793, val acc 89.13%\n",
      "iteration 11300, loss 0.157617, val acc 89.13%\n",
      "iteration 11400, loss 0.217937, val acc 89.13%\n",
      "iteration 11500, loss 0.148587, val acc 89.13%\n",
      "iteration 11600, loss 0.164923, val acc 89.13%\n",
      "iteration 11700, loss 0.146241, val acc 89.13%\n",
      "iteration 11800, loss 0.195981, val acc 89.13%\n",
      "iteration 11900, loss 0.186216, val acc 89.13%\n",
      "iteration 12000, loss 0.159678, val acc 89.13%\n",
      "iteration 12100, loss 0.193849, val acc 89.13%\n",
      "iteration 12200, loss 0.159247, val acc 89.13%\n",
      "iteration 12300, loss 0.185385, val acc 89.13%\n",
      "iteration 12400, loss 0.158400, val acc 89.13%\n",
      "iteration 12500, loss 0.173014, val acc 89.13%\n",
      "iteration 12600, loss 0.149438, val acc 89.13%\n",
      "iteration 12700, loss 0.208233, val acc 89.13%\n",
      "iteration 12800, loss 0.146753, val acc 89.13%\n",
      "iteration 12900, loss 0.126220, val acc 89.13%\n",
      "iteration 13000, loss 0.137553, val acc 89.13%\n",
      "iteration 13100, loss 0.161160, val acc 89.13%\n",
      "iteration 13200, loss 0.132333, val acc 89.13%\n",
      "iteration 13300, loss 0.153102, val acc 89.13%\n",
      "iteration 13400, loss 0.164630, val acc 89.13%\n",
      "iteration 13500, loss 0.235180, val acc 89.13%\n",
      "iteration 13600, loss 0.164842, val acc 89.13%\n",
      "iteration 13700, loss 0.175886, val acc 89.13%\n",
      "iteration 13800, loss 0.151214, val acc 89.13%\n",
      "iteration 13900, loss 0.205151, val acc 89.13%\n",
      "iteration 14000, loss 0.171738, val acc 89.13%\n",
      "iteration 14100, loss 0.217953, val acc 89.13%\n",
      "iteration 14200, loss 0.138882, val acc 89.13%\n",
      "iteration 14300, loss 0.227099, val acc 89.13%\n",
      "iteration 14400, loss 0.166024, val acc 89.13%\n",
      "iteration 14500, loss 0.149242, val acc 89.13%\n",
      "iteration 14600, loss 0.155825, val acc 89.13%\n",
      "iteration 14700, loss 0.262072, val acc 89.13%\n",
      "iteration 14800, loss 0.215540, val acc 89.13%\n",
      "iteration 14900, loss 0.121798, val acc 89.13%\n"
     ]
    }
   ],
   "source": [
    "loss_history = []\n",
    "loss_val_history = []\n",
    "for it in range(num_iters):\n",
    "    X_batch = None\n",
    "    y_batch = None\n",
    "    ################################################################################\n",
    "    # TODO: Sample batch_size elements from the training data and their            #\n",
    "    # corresponding labels to use in this round of gradient descent.               #\n",
    "    # Store the data in X_batch and their corresponding labels in                  #\n",
    "    # y_batch; after sampling X_batch should have shape (batch_size, n_features)   #\n",
    "    # and y_batch should have shape (batch_size,)                                  #\n",
    "    #                                                                              #\n",
    "    # Hint: Use np.random.choice to generate indices. Sampling with                #\n",
    "    # replacement is faster than sampling without replacement.                     #\n",
    "    ################################################################################\n",
    "\n",
    "    indices = np.random.choice(len(X_train),batch_size,replace=True)\n",
    "    X_batch = np.take(X_train,indices, axis = 0)\n",
    "    y_batch = np.take(y_train,indices, axis = 0)\n",
    "\n",
    "    ################################################################################\n",
    "    #                                 END OF YOUR CODE                             #\n",
    "    ################################################################################\n",
    "    loss = model.loss(X_batch, y_batch, reg_coeff)\n",
    "    loss_val = model.loss(X_val, y_val, reg_coeff)\n",
    "    if it % 100 == 0:\n",
    "        val_preds =  model.predict(X_val)\n",
    "        print('iteration %d, loss %f, val acc %.2f%%' % (it, loss,  accuracy_score(y_val,val_preds) * 100))\n",
    "    model.update_weights(X_batch, y_batch, learning_rate , reg_coeff)\n",
    "    loss_history.append(loss)\n",
    "    loss_val_history.append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####################################################################################\n",
    "# TODO: using matplotlib.pyplot package plot the training loss and validation loss #\n",
    "\n",
    "####################################################################################\n",
    "\n",
    "x = [i for i in range(15000) if i%100 == 0 ]\n",
    "y1 = [loss_val_history[i] for i in x]\n",
    "y2 = [loss_history[i] for i in x]\n",
    "plt.plot(x, y1)\n",
    "plt.plot(x, y2)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.title('loss value for SVM')\n",
    "plt.show()\n",
    "\n",
    "####################################################################################\n",
    "#                                 END OF YOUR CODE                                 #\n",
    "####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3:\n",
    "Explain why we see fluctuation in this plot?<br>\n",
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2. Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now, you should know how to use and how to implement SVM from scratch.\n",
    "In fact, for perceptron we can use premade functions as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[71  1]\n",
      " [19 23]]\n",
      "test acc 82.46%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "val_preds = clf.predict(X_test)\n",
    "print(confusion_matrix(y_test,val_preds,[1,-1]))\n",
    "print('test acc %.2f%%' % (accuracy_score(y_test,val_preds) * 100)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4:\n",
    "It is time for you to write your own code instead of completing some parts of a premade code.<br>\n",
    "So you can not use any premade functions like the previous cell.\n",
    "Write your code in the end of this .ipynb file <br>\n",
    "You should make your model and use that to build these outputs:<br>\n",
    "1- Report loss of training and accuracy of validation data on each epoch of training process.<br>\n",
    "2- You are allowed to use any normalization approach if need be.<br>\n",
    "3- Plot your training and validation loss vs number of iterations in one plot.<br>\n",
    "4- Finally print your confusion matrix and accuracy for your testing set.<br>\n",
    "With changing your hyperparameters try to get a good and reasonable accuracy and confusion matrix on testing set (similar to the accuracy when we used the package)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0, loss 1.026162, val acc 69.57%\n",
      "iteration 100, loss 0.857954, val acc 91.30%\n",
      "iteration 200, loss 0.849731, val acc 91.30%\n",
      "iteration 300, loss 0.831598, val acc 89.13%\n",
      "iteration 400, loss 0.830867, val acc 89.13%\n",
      "iteration 500, loss 0.829843, val acc 91.30%\n",
      "iteration 600, loss 0.824751, val acc 91.30%\n",
      "iteration 700, loss 0.828516, val acc 91.30%\n",
      "iteration 800, loss 0.829869, val acc 91.30%\n",
      "iteration 900, loss 0.843370, val acc 91.30%\n",
      "iteration 1000, loss 0.835766, val acc 91.30%\n",
      "iteration 1100, loss 0.836951, val acc 91.30%\n",
      "iteration 1200, loss 0.839091, val acc 91.30%\n",
      "iteration 1300, loss 0.836894, val acc 91.30%\n",
      "iteration 1400, loss 0.829690, val acc 93.48%\n",
      "iteration 1500, loss 0.830512, val acc 93.48%\n",
      "iteration 1600, loss 0.841449, val acc 93.48%\n",
      "iteration 1700, loss 0.841349, val acc 91.30%\n",
      "iteration 1800, loss 0.842493, val acc 91.30%\n",
      "iteration 1900, loss 0.841705, val acc 93.48%\n",
      "iteration 2000, loss 0.843009, val acc 91.30%\n",
      "iteration 2100, loss 0.857153, val acc 91.30%\n",
      "iteration 2200, loss 0.842307, val acc 93.48%\n",
      "iteration 2300, loss 0.840038, val acc 93.48%\n",
      "iteration 2400, loss 0.835313, val acc 93.48%\n",
      "iteration 2500, loss 0.844868, val acc 91.30%\n",
      "iteration 2600, loss 0.836178, val acc 91.30%\n",
      "iteration 2700, loss 0.843813, val acc 91.30%\n",
      "iteration 2800, loss 0.844810, val acc 91.30%\n",
      "iteration 2900, loss 0.842067, val acc 91.30%\n",
      "iteration 3000, loss 0.830833, val acc 93.48%\n",
      "iteration 3100, loss 0.832649, val acc 93.48%\n",
      "iteration 3200, loss 0.833097, val acc 91.30%\n",
      "iteration 3300, loss 0.843139, val acc 91.30%\n",
      "iteration 3400, loss 0.830053, val acc 93.48%\n",
      "iteration 3500, loss 0.831911, val acc 91.30%\n",
      "iteration 3600, loss 0.839546, val acc 91.30%\n",
      "iteration 3700, loss 0.830340, val acc 93.48%\n",
      "iteration 3800, loss 0.839966, val acc 91.30%\n",
      "iteration 3900, loss 0.829750, val acc 93.48%\n",
      "iteration 4000, loss 0.838483, val acc 93.48%\n",
      "iteration 4100, loss 0.833306, val acc 93.48%\n",
      "iteration 4200, loss 0.833055, val acc 93.48%\n",
      "iteration 4300, loss 0.847148, val acc 91.30%\n",
      "iteration 4400, loss 0.844244, val acc 93.48%\n",
      "iteration 4500, loss 0.840890, val acc 93.48%\n",
      "iteration 4600, loss 0.845534, val acc 93.48%\n",
      "iteration 4700, loss 0.840618, val acc 93.48%\n",
      "iteration 4800, loss 0.844008, val acc 93.48%\n",
      "iteration 4900, loss 0.844409, val acc 93.48%\n",
      "iteration 5000, loss 0.838878, val acc 93.48%\n",
      "iteration 5100, loss 0.836702, val acc 93.48%\n",
      "iteration 5200, loss 0.838721, val acc 93.48%\n",
      "iteration 5300, loss 0.841411, val acc 93.48%\n",
      "iteration 5400, loss 0.842240, val acc 93.48%\n",
      "iteration 5500, loss 0.840970, val acc 93.48%\n",
      "iteration 5600, loss 0.840973, val acc 93.48%\n",
      "iteration 5700, loss 0.840233, val acc 95.65%\n",
      "iteration 5800, loss 0.846890, val acc 91.30%\n",
      "iteration 5900, loss 0.836966, val acc 93.48%\n",
      "iteration 6000, loss 0.847237, val acc 91.30%\n",
      "iteration 6100, loss 0.840344, val acc 93.48%\n",
      "iteration 6200, loss 0.835914, val acc 93.48%\n",
      "iteration 6300, loss 0.839543, val acc 93.48%\n",
      "iteration 6400, loss 0.838886, val acc 95.65%\n",
      "iteration 6500, loss 0.836581, val acc 93.48%\n",
      "iteration 6600, loss 0.848015, val acc 91.30%\n",
      "iteration 6700, loss 0.838100, val acc 93.48%\n",
      "iteration 6800, loss 0.847626, val acc 91.30%\n",
      "iteration 6900, loss 0.842721, val acc 93.48%\n",
      "iteration 7000, loss 0.847252, val acc 91.30%\n",
      "iteration 7100, loss 0.848913, val acc 91.30%\n",
      "iteration 7200, loss 0.843701, val acc 93.48%\n",
      "iteration 7300, loss 0.849710, val acc 91.30%\n",
      "iteration 7400, loss 0.850787, val acc 91.30%\n",
      "iteration 7500, loss 0.843781, val acc 93.48%\n",
      "iteration 7600, loss 0.847596, val acc 93.48%\n",
      "iteration 7700, loss 0.843719, val acc 93.48%\n",
      "iteration 7800, loss 0.847977, val acc 93.48%\n",
      "iteration 7900, loss 0.849053, val acc 91.30%\n",
      "iteration 8000, loss 0.844329, val acc 93.48%\n",
      "iteration 8100, loss 0.844973, val acc 93.48%\n",
      "iteration 8200, loss 0.844745, val acc 95.65%\n",
      "iteration 8300, loss 0.847861, val acc 93.48%\n",
      "iteration 8400, loss 0.846779, val acc 93.48%\n",
      "iteration 8500, loss 0.850357, val acc 93.48%\n",
      "iteration 8600, loss 0.853887, val acc 91.30%\n",
      "iteration 8700, loss 0.845394, val acc 93.48%\n",
      "iteration 8800, loss 0.853878, val acc 91.30%\n",
      "iteration 8900, loss 0.843861, val acc 95.65%\n",
      "iteration 9000, loss 0.851895, val acc 91.30%\n",
      "iteration 9100, loss 0.844886, val acc 93.48%\n",
      "iteration 9200, loss 0.842199, val acc 93.48%\n",
      "iteration 9300, loss 0.844636, val acc 93.48%\n",
      "iteration 9400, loss 0.844796, val acc 93.48%\n",
      "iteration 9500, loss 0.835560, val acc 93.48%\n",
      "iteration 9600, loss 0.828731, val acc 93.48%\n",
      "iteration 9700, loss 0.830638, val acc 93.48%\n",
      "iteration 9800, loss 0.830100, val acc 95.65%\n",
      "iteration 9900, loss 0.831015, val acc 93.48%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP : 70 TN : 33 FP : 9 FN : 2\n",
      "acc : 90.35087719298247\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Perceptron() :\n",
    "    \n",
    "    def __init__(self, n_features: int, std: float):\n",
    "    \n",
    "        self.n_features = n_features\n",
    "        self.w = np.random.normal(0,std,self.n_features)\n",
    "    \n",
    "    def loss(self, X: np.ndarray, y: np.ndarray):\n",
    "    \n",
    "        loss = 0.0\n",
    "        s = np.dot(X,self.w)\n",
    "        s2 = s * y\n",
    "        ones_vector = np.ones(len(X))\n",
    "        zeros = np.zeros(len(X))\n",
    "        loss = ((1 / len(X)) * (sum(np.maximum(zeros, ones_vector - s2))))\n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def update_weights(self,  X: np.ndarray, y: np.ndarray, learning_rate: float):\n",
    "     \n",
    "        for i in range(len(X)) :\n",
    "                predicted_y = np.sign(np.dot(X[i], self.w))\n",
    "                if predicted_y == y[i] :\n",
    "                    continue\n",
    "                else :\n",
    "                    self.w = self.w + learning_rate * (y[i] * X[i])\n",
    "\n",
    "    def predict(self, X):\n",
    "        y_pred = None\n",
    "        y_pred = []\n",
    "        for i in range(len(X)) :\n",
    "            y_pred.append(np.sign(np.dot(X[i], self.w)))\n",
    "        return y_pred\n",
    "    \n",
    "    def calculate_accuracy(self, predicted_Y, real_Y):\n",
    "        acc = 0\n",
    "        for i, j in zip(predicted_Y, real_Y):\n",
    "            if i == j:\n",
    "                acc += 1\n",
    "                \n",
    "        return acc / len(predicted_Y)\n",
    "    \n",
    "std = 0.0001\n",
    "num_iters = 10000\n",
    "learning_rate = 1e-7\n",
    "\n",
    "model = Perceptron(n_features=X_train.shape[1], std= std )\n",
    "loss_history = []\n",
    "loss_val_history = []\n",
    "for it in range(num_iters):\n",
    "    loss = model.loss(X_train, y_train)\n",
    "    loss_val = model.loss(X_val, y_val)\n",
    "    if it % 100 == 0:\n",
    "        val_preds =  model.predict(X_val)\n",
    "        print('iteration %d, loss %f, val acc %.2f%%' % (it, loss, model.calculate_accuracy(y_val,val_preds) * 100))\n",
    "    model.update_weights(X_train, y_train, learning_rate)\n",
    "    loss_history.append(loss)\n",
    "    loss_val_history.append(loss_val)\n",
    "\n",
    "x = [i for i in range(num_iters) if i%10 == 0 ]\n",
    "y1 = [loss_val_history[i] for i in x]\n",
    "y2 = [loss_history[i] for i in x]\n",
    "plt.plot(x, y1)\n",
    "plt.plot(x, y2)\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.title('loss value for SVM')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "val_preds = model.predict(X_test)\n",
    "TP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "FP = 0\n",
    "for i, j in zip(val_preds, y_test):\n",
    "    if i == 1 and j == 1:\n",
    "        TP += 1\n",
    "    elif i == -1 and j == -1:\n",
    "        TN += 1\n",
    "    elif i == 1 and j == -1:\n",
    "        FP += 1\n",
    "    elif i == -1 and j == 1:\n",
    "        FN += 1\n",
    "\n",
    "print(\"TP :\",TP,\"TN :\",TN,\"FP :\",FP, \"FN :\",FN)\n",
    "print(\"acc :\",model. calculate_accuracy(val_preds,y_test) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
